<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Ethics on Gradient.</title><link>https://thegradient.ink/tags/ethics/</link><description>Recent content in Ethics on Gradient.</description><image><title>Gradient.</title><url>https://thegradient.ink/images/Gradient-social-logo.png</url><link>https://thegradient.ink/images/Gradient-social-logo.png</link></image><generator>Hugo -- 0.128.0</generator><language>en-us</language><lastBuildDate>Mon, 07 Apr 2025 08:30:00 -0700</lastBuildDate><atom:link href="https://thegradient.ink/tags/ethics/index.xml" rel="self" type="application/rss+xml"/><item><title>AI is Decoupling From Ethics: Why should you care?</title><link>https://thegradient.ink/posts/my-first-post/</link><pubDate>Mon, 07 Apr 2025 08:30:00 -0700</pubDate><guid>https://thegradient.ink/posts/my-first-post/</guid><description>What&amp;rsquo;s currently top of mind for me: AI is advancing insanely fast. Faster than any of us ever expected.
The CEO of Anthropic predicted that by the end of 2025 over 90% of all software will be written by AI.
Whether that number proves true or not, the trajectory is clear.
I don&amp;rsquo;t think enough of us in university are thinking critically about the implications of this, as it will radically disrupt our lives in the next decade, regardless of what industry or profession you are in.</description></item></channel></rss>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI is Decoupling From Ethics: Why should you care? | Gradient.</title>
<meta name=keywords content="AI,Ethics,Data,Opinion"><meta name=description content="What&rsquo;s currently top of mind for me: AI is advancing insanely fast. Faster than any of us ever expected.
The CEO of Anthropic predicted that by the end of 2025 over 90% of all software will be written by AI.
Whether that number proves true or not, the trajectory is clear.
I don&rsquo;t think enough of us in university are thinking critically about the implications of this, as it will radically disrupt our lives in the next decade, regardless of what industry or profession you are in."><meta name=author content="Thomas Emnetu"><link rel=canonical href=https://thegradient.ink/posts/my-first-post/><link crossorigin=anonymous href=/assets/css/stylesheet.0e0a4a7e262f784d10323d22de959ebc81f1bc53e002a018f98d9062377139ac.css integrity="sha256-DgpKfiYveE0QMj0i3pWevIHxvFPgAqAY+Y2QYjdxOaw=" rel="preload stylesheet" as=style><link rel=icon href=https://thegradient.ink/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://thegradient.ink/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://thegradient.ink/favicon-32x32.png><link rel=apple-touch-icon href=https://thegradient.ink/apple-touch-icon.png><link rel=mask-icon href=https://thegradient.ink/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://thegradient.ink/posts/my-first-post/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script data-goatcounter=https://thegradient.goatcounter.com/count async src=//gc.zgo.at/count.js></script><meta property="og:url" content="https://thegradient.ink/posts/my-first-post/"><meta property="og:site_name" content="Gradient."><meta property="og:title" content="AI is Decoupling From Ethics: Why should you care?"><meta property="og:description" content="What’s currently top of mind for me: AI is advancing insanely fast. Faster than any of us ever expected.
The CEO of Anthropic predicted that by the end of 2025 over 90% of all software will be written by AI.
Whether that number proves true or not, the trajectory is clear.
I don’t think enough of us in university are thinking critically about the implications of this, as it will radically disrupt our lives in the next decade, regardless of what industry or profession you are in."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-07T08:30:00-07:00"><meta property="article:modified_time" content="2025-04-07T08:30:00-07:00"><meta property="article:tag" content="AI"><meta property="article:tag" content="Ethics"><meta property="article:tag" content="Data"><meta property="article:tag" content="Opinion"><meta property="og:image" content="https://thegradient.ink/images/gradient-og.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://thegradient.ink/images/gradient-og.png"><meta name=twitter:title content="AI is Decoupling From Ethics: Why should you care?"><meta name=twitter:description content="What&rsquo;s currently top of mind for me: AI is advancing insanely fast. Faster than any of us ever expected.
The CEO of Anthropic predicted that by the end of 2025 over 90% of all software will be written by AI.
Whether that number proves true or not, the trajectory is clear.
I don&rsquo;t think enough of us in university are thinking critically about the implications of this, as it will radically disrupt our lives in the next decade, regardless of what industry or profession you are in."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://thegradient.ink/posts/"},{"@type":"ListItem","position":2,"name":"AI is Decoupling From Ethics: Why should you care?","item":"https://thegradient.ink/posts/my-first-post/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AI is Decoupling From Ethics: Why should you care?","name":"AI is Decoupling From Ethics: Why should you care?","description":"What\u0026rsquo;s currently top of mind for me: AI is advancing insanely fast. Faster than any of us ever expected.\nThe CEO of Anthropic predicted that by the end of 2025 over 90% of all software will be written by AI.\nWhether that number proves true or not, the trajectory is clear.\nI don\u0026rsquo;t think enough of us in university are thinking critically about the implications of this, as it will radically disrupt our lives in the next decade, regardless of what industry or profession you are in.","keywords":["AI","Ethics","Data","Opinion"],"articleBody":"What’s currently top of mind for me: AI is advancing insanely fast. Faster than any of us ever expected.\nThe CEO of Anthropic predicted that by the end of 2025 over 90% of all software will be written by AI.\nWhether that number proves true or not, the trajectory is clear.\nI don’t think enough of us in university are thinking critically about the implications of this, as it will radically disrupt our lives in the next decade, regardless of what industry or profession you are in.\nI believe the goal post of what is deemed “AGI” will be continuously pushed back each year as these models continue to shock everyone with the sophistication of their outputs.\nBut we only arrive at better outputs with better inputs. I find myself often questioning the ethics of data acquisition that these incumbents are taking to advance their models at such a rapid pace.\nSo what does this mean for the future? There no longer is a “moat” for design or development. These highly differentiated products are heavily predicated on the data they have access to and their ability to extract maximum value from it as an input. Thus creating better outputs as a result.\nIt’s only logical to assume that at the exponential scale these models are improving, their data inputs are exponentially scaling with them.\nEarly GPT-3 models were essentially trained on the general internet and the majority of books in existence. So what new/untapped data is left to continue this exponential curve?\nWe’ve seen stagnation in the innovation of many of these American-based tech companies. With models from Deepseek, Alibaba, Manus, etc. outpacing the growth of Google, OpenAI, xAI, etc.\nI think it’s inevitable that a startup will be born in the name of governing over the 149+ zettabytes of data that currently exist on the internet.\nIt’s currently impossible to detect whether an artist/designer/animator’s, etc. work was used to train a model — unless you’re a prominent figure with extensive high-quality public work such as Hayao Miyazaki.\nThe decoupling from ethics has begun The most prime example of this has been demonstrated recently with OpenAI’s update to GPT-4o image generation. It’s safe to assume that the model was trained extensively on the life work of Hayao Miyazaki in order to accurately create “Studio-Ghibli style images.”\nWe can only speculate on if Miyazaki agreed to this and was compensated, or if his public works were simply scraped into a database.\nI fear the line of what constitutes ethical data practices will continue to be blurred amidst this AI rush we are in.\nI hope those of us who have the privilege to work on these tools remain cognizant of how these injustices may present themselves and actively work to mitigate them.\nHaving these conversations is critical. Suffocating the injustices we commit with innovation will prove to cause more harm to society than good in due time.\nI’m largely shaken up by these recent events surrounding GPT-4o’s new image generation. It signals to me a decoupling from technology and ethics. This should have people in these spaces seriously concerned.\nA future where these corporations feel entitled to do as they please with data that is not theirs, so long as it’s creating value for users and shareholders, is a scary future.\nThis is not just an opinion OpenAI added over 1M paying users in a single hour after Studio Ghibli-style images generated with GPT-4o started trending everywhere. The biggest spike in paid users since the launch of their paid plan. Which ultimately allowed them to raise $40B at a $300B valuation a week later.\nThat should tell you everything. Most don’t care how the model was trained. They care about cool outputs that grow KPIs they can brag about.\nI’m one of the most optimistic people about the future use-cases of AI and what it will enable us to do. But we must ask ourselves: at what cost?\nIt seems those in power don’t care about the cost, but rather endlessly one-upping each other on the metrics of their new LLM iteration every quarter: all to convince VCs and PE that they are getting a return like no other on their investment. Therefore allowing them to raise more money at an inflated valuation, enabling the cycle to continue.\nMy ethical dilemma In short, I’m conflicted with where I stand in all of this.\nBeing an incoming UX Designer at Microsoft, I can’t help but think I’m enabling this malpractice. But having no power to push real change in this industry feels asphyxiating.\nNonetheless, it reinstates vigor in me. I’m eager to do all I can, with the little power I have. Except I don’t know where to start or how.\nThus, I feel documenting my thoughts, opinions, and perspective is the least action I can take — in hopes that I’m not alone in this sentiment.\nmore from me soon :/\n","wordCount":"820","inLanguage":"en","image":"https://thegradient.ink/images/gradient-og.png","datePublished":"2025-04-07T08:30:00-07:00","dateModified":"2025-04-07T08:30:00-07:00","author":[{"@type":"Person","name":"Thomas Emnetu"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://thegradient.ink/posts/my-first-post/"},"publisher":{"@type":"Organization","name":"Gradient.","logo":{"@type":"ImageObject","url":"https://thegradient.ink/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://thegradient.ink/ accesskey=h title="Gradient. (Alt + H)"><img src=https://thegradient.ink/images/temnetu-logo.svg alt aria-label=logo height=55>Gradient.</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://thegradient.ink/>Home</a>&nbsp;»&nbsp;<a href=https://thegradient.ink/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">AI is Decoupling From Ethics: Why should you care?</h1><div class=post-meta><span title='2025-04-07 08:30:00 -0700 -0700'>April 7, 2025</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Thomas Emnetu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#whats-currently-top-of-mind-for-me aria-label="What&rsquo;s currently top of mind for me:">What&rsquo;s currently top of mind for me:</a></li><li><a href=#so-what-does-this-mean-for-the-future aria-label="So what does this mean for the future?">So what does this mean for the future?</a></li><li><a href=#the-decoupling-from-ethics-has-begun aria-label="The decoupling from ethics has begun">The decoupling from ethics has begun</a></li><li><a href=#this-is-not-just-an-opinion aria-label="This is not just an opinion">This is not just an opinion</a></li><li><a href=#my-ethical-dilemma aria-label="My ethical dilemma">My ethical dilemma</a></li></ul></div></details></div><div class=post-content><h2 id=whats-currently-top-of-mind-for-me>What&rsquo;s currently top of mind for me:<a hidden class=anchor aria-hidden=true href=#whats-currently-top-of-mind-for-me>#</a></h2><p>AI is advancing insanely fast. Faster than any of us ever expected.</p><p>The CEO of Anthropic predicted that <a href=https://www.businessinsider.com/anthropic-ceo-ai-90-percent-code-3-to-6-months-2025-3>by the end of 2025 over 90% of all software will be written by AI.</a></p><p>Whether that number proves true or not, the trajectory is clear.</p><p>I don&rsquo;t think enough of us in university are thinking critically about the implications of this, as it will radically disrupt our lives in the next decade, regardless of what industry or profession you are in.</p><p>I believe the goal post of what is deemed &ldquo;AGI&rdquo; will be continuously pushed back each year as these models continue to shock everyone with the sophistication of their outputs.</p><p>But <strong>we only arrive at better outputs with better inputs.</strong> I find myself often questioning the ethics of data acquisition that these incumbents are taking to advance their models at such a rapid pace.</p><h2 id=so-what-does-this-mean-for-the-future>So what does this mean for the future?<a hidden class=anchor aria-hidden=true href=#so-what-does-this-mean-for-the-future>#</a></h2><p><strong>There no longer is a &ldquo;moat&rdquo; for design or development.</strong> These highly differentiated products are heavily predicated on the data they have access to and their ability to extract maximum value from it as an input. Thus creating better outputs as a result.</p><p>It&rsquo;s only logical to assume that at the exponential scale these models are improving, their data inputs are exponentially scaling with them.</p><p><img alt="Scaling Laws in Language Modeling" loading=lazy src=/images/scaling-laws.jpg></p><p>Early GPT-3 models were essentially trained on the general internet and the majority of books in existence. <strong>So what new/untapped data is left to continue this exponential curve?</strong></p><p>We&rsquo;ve seen stagnation in the innovation of many of these American-based tech companies. With models from Deepseek, Alibaba, Manus, etc. outpacing the growth of Google, OpenAI, xAI, etc.</p><p>I think it&rsquo;s inevitable that a startup will be born in the name of governing over the 149+ zettabytes of data that currently exist on the internet.</p><p>It&rsquo;s currently impossible to detect whether an artist/designer/animator’s, etc. work was used to train a model — unless you&rsquo;re a prominent figure with extensive high-quality public work such as Hayao Miyazaki.</p><h2 id=the-decoupling-from-ethics-has-begun>The decoupling from ethics has begun<a hidden class=anchor aria-hidden=true href=#the-decoupling-from-ethics-has-begun>#</a></h2><p>The most prime example of this has been demonstrated recently with OpenAI&rsquo;s update to GPT-4o image generation. It&rsquo;s safe to assume that the model was trained extensively on the life work of Hayao Miyazaki in order to accurately create &ldquo;Studio-Ghibli style images.&rdquo;</p><p>We can only speculate on if Miyazaki agreed to this and was compensated, or if his public works were simply scraped into a database.</p><p><strong>I fear the line of what constitutes ethical data practices will continue to be blurred amidst this AI rush we are in.</strong></p><p>I hope those of us who have the privilege to work on these tools remain cognizant of how these injustices may present themselves and actively work to mitigate them.</p><p>Having these conversations is critical. Suffocating the injustices we commit with innovation will prove to cause more harm to society than good in due time.</p><p>I&rsquo;m largely shaken up by these recent events surrounding GPT-4o&rsquo;s new image generation. It signals to me a decoupling from technology and ethics. This should have people in these spaces seriously concerned.</p><p>A future where these corporations feel entitled to do as they please with data that is not theirs, so long as it&rsquo;s creating value for users and shareholders, is a scary future.</p><h2 id=this-is-not-just-an-opinion>This is not just an opinion<a hidden class=anchor aria-hidden=true href=#this-is-not-just-an-opinion>#</a></h2><p><a href=https://www.theverge.com/openai/639960/chatgpt-added-one-million-users-in-the-last-hour>OpenAI added over 1M paying users in a single hour</a> after Studio Ghibli-style images generated with GPT-4o started trending everywhere. The biggest spike in paid users since the launch of their paid plan. Which <a href=https://www.cnbc.com/2025/03/31/openai-closes-40-billion-in-funding-the-largest-private-fundraise-in-history-softbank-chatgpt.html>ultimately allowed them to raise $40B at a $300B valuation a week later.</a></p><p>That should tell you everything. Most don&rsquo;t care how the model was trained. They care about cool outputs that grow KPIs they can brag about.</p><p>I&rsquo;m one of the most optimistic people about the future use-cases of AI and what it will enable us to do. <strong>But we must ask ourselves: at what cost?</strong></p><p>It seems those in power don&rsquo;t care about the cost, but rather endlessly one-upping each other on the metrics of their new LLM iteration every quarter: all to convince VCs and PE that they are getting a return like no other on their investment. Therefore allowing them to raise more money at an inflated valuation, enabling the cycle to continue.</p><h2 id=my-ethical-dilemma>My ethical dilemma<a hidden class=anchor aria-hidden=true href=#my-ethical-dilemma>#</a></h2><p>In short, I&rsquo;m conflicted with where I stand in all of this.</p><p>Being an incoming UX Designer at Microsoft, I can&rsquo;t help but think I&rsquo;m enabling this malpractice. But having no power to push real change in this industry feels asphyxiating.</p><p>Nonetheless, it reinstates vigor in me. I&rsquo;m eager to do all I can, with the little power I have. Except I don&rsquo;t know where to start or how.</p><p>Thus, I feel documenting my thoughts, opinions, and perspective is the least action I can take — in hopes that I&rsquo;m not alone in this sentiment.</p><p>more from me soon :/</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://thegradient.ink/tags/ai/>AI</a></li><li><a href=https://thegradient.ink/tags/ethics/>Ethics</a></li><li><a href=https://thegradient.ink/tags/data/>Data</a></li><li><a href=https://thegradient.ink/tags/opinion/>Opinion</a></li></ul><nav class=paginav><a class=prev href=https://thegradient.ink/posts/my-second-post/><span class=title>« Prev</span><br><span>Why most college students won’t make it in big tech</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://thegradient.ink/>Gradient.</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
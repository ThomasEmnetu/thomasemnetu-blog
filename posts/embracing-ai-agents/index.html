<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>I’ve been drinking the AI kool-aid…and I love it | Gradient.</title>
<meta name=keywords content="Multi-Agents,Opinion,Productivity,Dev"><meta name=description content="I was overly pessimistic about AI for a while. I harped on the harms, ethical shortcomings, the ways this tech could be misused or cause real damage.
I still hold those concerns.
I assure you they haven&rsquo;t disappeared.
But I had a profound experience this week that shifted something fundamental in how I&rsquo;m thinking about this.
I deployed my first multi-agent swarm I had a vague product idea. No detailed spec, just a rough concept."><meta name=author content="Thomas Emnetu"><link rel=canonical href=https://thegradient.ink/posts/embracing-ai-agents/><link crossorigin=anonymous href=/assets/css/stylesheet.0e0a4a7e262f784d10323d22de959ebc81f1bc53e002a018f98d9062377139ac.css integrity="sha256-DgpKfiYveE0QMj0i3pWevIHxvFPgAqAY+Y2QYjdxOaw=" rel="preload stylesheet" as=style><link rel=icon href=https://thegradient.ink/favicon.png><link rel=icon type=image/png sizes=16x16 href=https://thegradient.ink/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://thegradient.ink/favicon-32x32.png><link rel=apple-touch-icon href=https://thegradient.ink/apple-touch-icon.png><link rel=mask-icon href=https://thegradient.ink/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://thegradient.ink/posts/embracing-ai-agents/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script data-goatcounter=https://thegradient.goatcounter.com/count async src=//gc.zgo.at/count.js></script><meta property="og:url" content="https://thegradient.ink/posts/embracing-ai-agents/"><meta property="og:site_name" content="Gradient."><meta property="og:title" content="I’ve been drinking the AI kool-aid…and I love it"><meta property="og:description" content="I was overly pessimistic about AI for a while. I harped on the harms, ethical shortcomings, the ways this tech could be misused or cause real damage.
I still hold those concerns.
I assure you they haven’t disappeared.
But I had a profound experience this week that shifted something fundamental in how I’m thinking about this.
I deployed my first multi-agent swarm I had a vague product idea. No detailed spec, just a rough concept."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-07T01:00:00-07:00"><meta property="article:modified_time" content="2026-02-07T01:00:00-07:00"><meta property="article:tag" content="Multi-Agents"><meta property="article:tag" content="Opinion"><meta property="article:tag" content="Productivity"><meta property="article:tag" content="Dev"><meta property="og:image" content="https://thegradient.ink/images/gradient-og.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://thegradient.ink/images/gradient-og.png"><meta name=twitter:title content="I’ve been drinking the AI kool-aid…and I love it"><meta name=twitter:description content="I was overly pessimistic about AI for a while. I harped on the harms, ethical shortcomings, the ways this tech could be misused or cause real damage.
I still hold those concerns.
I assure you they haven&rsquo;t disappeared.
But I had a profound experience this week that shifted something fundamental in how I&rsquo;m thinking about this.
I deployed my first multi-agent swarm I had a vague product idea. No detailed spec, just a rough concept."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://thegradient.ink/posts/"},{"@type":"ListItem","position":2,"name":"I’ve been drinking the AI kool-aid…and I love it","item":"https://thegradient.ink/posts/embracing-ai-agents/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"I’ve been drinking the AI kool-aid…and I love it","name":"I’ve been drinking the AI kool-aid…and I love it","description":"I was overly pessimistic about AI for a while. I harped on the harms, ethical shortcomings, the ways this tech could be misused or cause real damage.\nI still hold those concerns.\nI assure you they haven\u0026rsquo;t disappeared.\nBut I had a profound experience this week that shifted something fundamental in how I\u0026rsquo;m thinking about this.\nI deployed my first multi-agent swarm I had a vague product idea. No detailed spec, just a rough concept.","keywords":["Multi-Agents","Opinion","Productivity","Dev"],"articleBody":"I was overly pessimistic about AI for a while. I harped on the harms, ethical shortcomings, the ways this tech could be misused or cause real damage.\nI still hold those concerns.\nI assure you they haven’t disappeared.\nBut I had a profound experience this week that shifted something fundamental in how I’m thinking about this.\nI deployed my first multi-agent swarm I had a vague product idea. No detailed spec, just a rough concept.\nI set up a simple multi-agent system as the following:\nPM agent to define scope backend agent to build server side frontend agent to handle the UI QA agent to catch issues Then I stepped back.\nFor over 30 minutes, I barely touched my keyboard; after enabling auto-approval for the session.\nThe agents coordinated. Delegated tasks to each other. Built a database schema. Wrote frontend code. When things broke, they debugged and self-corrected.\nIn under 60 minutes, I had a working product. Backend running, UI rendering, everything functional end-to-end.\nI’ve tried AI coding tools before, but this was fundamentally different. Don’t get me wrong, the output wasn’t perfect production level code. But the autonomous coordination actually worked.\nI’m not here to be a grifter I’m not gonna say “AI will replace all developers” or “everyone can build anything now”; though the latter is becoming increasingly true.\nLet me be clear. The system isn’t magic. It made mistakes. It wrote code that needed refactoring.\nBut what surprised me was how the bottleneck wasn’t at all the models capabilities.\nIt was how I structured the problem.\nWhen I gave clear, specific scopes to each agent, they executed extraordinarily well.\nConversely, when I was vague, it caused them to spiral, still producing working code, but their bar for quality dropped.\nThe quality of output correlated directly with the quality of problem decomposition.\nThat’s a different skill than writing code.\nIt’s effectively architecting systems in an organized feedback loop.\nWhy this matters We often discuss AI progress in terms of model capabilities.\nWhich frontier model reasons the best, creates the best outputs, has the highest benchmark scores, etc.\nBut they are all so good now that you can disregard marginal gains one may receive by using a specific LLM.\nOrchestration is becoming the most valuable skill, i.e. systems thinking.\nMulti-agent systems aren’t new conceptually. The idea of breaking work into specialized sub-tasks and coordinating them has been around for years.\nWhat changed is that the models are now good enough (and inference is cheap enough) that orchestration actually works at a practical level.\nSpotify is now using this in production to resolve errors and conflicts. It’s become a critical part of their workflow, freeing up developer time for bigger-picture efforts.\nThe economics finally make sense.\nThe part I’m grappling with This creates real questions I don’t have answers to yet.\nIf the skill shifts from writing code to decomposing problems and directing agents what does expertise mean?\nHow do we maintain quality when the barrier to shipping is this low?\nWhat happens when non-technical people can orchestrate complex systems without understanding what’s happening under the hood?\nI used to believe the transition would be fairly gradual. Models getting better over years and workflows evolve incrementally, giving folks time to adapt.\nBut watching a multi-agent system go from nothing to a working product in an hour makes me realize the shift is more discontinuous than I expected.\nAt some point, you have to reflect on whether you are adapting or resisting.\nHistory as context Developers used punch cards to program from the 1940s-1970s.\nIBM keypunch machine used to punch holes into paper cards for early computer data entry and programming When CLIs and GUIs became standard, their expertise didn’t disappear.\nIt simply evolved.\nThe ones who “adapted” were not the ones who memorized punch card syntax.\nThey were the ones who understood the underlying problems \u0026 learned the new abstractions.\nSame pattern playing out again, just a different font.\nThe abstractions are shifting. The problems remain.\nWhat I’m doing about it I’m experimenting deliberately.\nReading everything I can. Building small swarms. Analyzing their points of failure. Talking to people who understand multi-agent architecture at a deeper level than I do.\nNot at all because I’m trying to stay ahead or worried about being left behind.\nBut because I’m genuinely trying to understand what’s actually possible versus what’s hype.\nAnd because the gap between demos and production reality is often massive.\nThe uncomfortable truth I titled this “I’ve been drinking the AI kool-aid” because that’s what it feels like.\nI’m more optimistic about multi-agent systems than I expected to be.\nBut optimism without critical examination is just hype.\nSo what I’m closely studying and paying attention to is:\nHow do these systems maintain context over longer sessions (i.e. days/weeks)? What is most optimal memory architecture to enable execution of more complex work? When one agent makes a mistake, how does that cascade through the system? These are some of the problems exciting me that’ve yet to be solved in the industry.\nMy perspective I have no idea where this goes from here.\nBut I just experienced something that changed how I think about what’s possible with current technology. It was imperative that I share it.\nRight now, with the tools that exist today, anyone can semantically orchestrate an autonomous multi-agent swarm that builds working software in less than an hour.\nThat’s worth your attention. Especially if you work in tech or aspire to.\nThe nature of the work is changing faster than most can adjust.\nSo what does this mean for us?\nI’m honestly trying to worry less about that.\nI’m much more concerned with challenging myself and feeding my curiosity, so my skills don’t atrophy.\nmore from me soon\n","wordCount":"959","inLanguage":"en","image":"https://thegradient.ink/images/gradient-og.png","datePublished":"2026-02-07T01:00:00-07:00","dateModified":"2026-02-07T01:00:00-07:00","author":[{"@type":"Person","name":"Thomas Emnetu"}],"mainEntityOfPage":{"@type":"WebPage","@id":"https://thegradient.ink/posts/embracing-ai-agents/"},"publisher":{"@type":"Organization","name":"Gradient.","logo":{"@type":"ImageObject","url":"https://thegradient.ink/favicon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://thegradient.ink/ accesskey=h title="Gradient. (Alt + H)"><img src=https://thegradient.ink/images/temnetu-logo.svg alt aria-label=logo height=55>Gradient.</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://thegradient.ink/>Home</a>&nbsp;»&nbsp;<a href=https://thegradient.ink/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">I’ve been drinking the AI kool-aid…and I love it</h1><div class=post-meta><span title='2026-02-07 01:00:00 -0700 -0700'>February 7, 2026</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;Thomas Emnetu</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#i-was-overly-pessimistic-about-ai-for-a-while aria-label="I was overly pessimistic about AI for a while.">I was overly pessimistic about AI for a while.</a></li><li><a href=#i-deployed-my-first-multi-agent-swarm aria-label="I deployed my first multi-agent swarm">I deployed my first multi-agent swarm</a></li><li><a href=#im-not-here-to-be-a-grifter aria-label="I&rsquo;m not here to be a grifter">I&rsquo;m not here to be a grifter</a></li><li><a href=#why-this-matters aria-label="Why this matters">Why this matters</a></li><li><a href=#the-part-im-grappling-with aria-label="The part I&rsquo;m grappling with">The part I&rsquo;m grappling with</a></li><li><a href=#history-as-context aria-label="History as context">History as context</a></li><li><a href=#what-im-doing-about-it aria-label="What I&rsquo;m doing about it">What I&rsquo;m doing about it</a></li><li><a href=#the-uncomfortable-truth aria-label="The uncomfortable truth">The uncomfortable truth</a></li><li><a href=#my-perspective aria-label="My perspective">My perspective</a></li></ul></div></details></div><div class=post-content><h2 id=i-was-overly-pessimistic-about-ai-for-a-while>I was overly pessimistic about AI for a while.<a hidden class=anchor aria-hidden=true href=#i-was-overly-pessimistic-about-ai-for-a-while>#</a></h2><p>I harped on the harms, ethical shortcomings, the ways this tech could be misused or cause real damage.</p><p>I still hold those concerns.</p><p>I assure you they haven&rsquo;t disappeared.</p><p>But I had a profound experience this week that shifted something fundamental in how I&rsquo;m thinking about this.</p><h2 id=i-deployed-my-first-multi-agent-swarm>I deployed my first multi-agent swarm<a hidden class=anchor aria-hidden=true href=#i-deployed-my-first-multi-agent-swarm>#</a></h2><p>I had a vague product idea. No detailed spec, just a rough concept.</p><p>I set up a simple multi-agent system as the following:</p><ul><li>PM agent to define scope</li><li>backend agent to build server side</li><li>frontend agent to handle the UI</li><li>QA agent to catch issues</li></ul><p>Then I stepped back.</p><p>For over 30 minutes, I barely touched my keyboard; after enabling auto-approval for the session.</p><p>The agents coordinated. Delegated tasks to each other. Built a database schema. Wrote frontend code. When things broke, they debugged and self-corrected.</p><p>In under 60 minutes, I had a working product. Backend running, UI rendering, everything functional end-to-end.</p><p>I&rsquo;ve tried AI coding tools before, but this was fundamentally different. Don&rsquo;t get me wrong, the output wasn&rsquo;t perfect production level code. But the autonomous <strong>coordination</strong> actually worked.</p><h2 id=im-not-here-to-be-a-grifter>I&rsquo;m not here to be a grifter<a hidden class=anchor aria-hidden=true href=#im-not-here-to-be-a-grifter>#</a></h2><p>I&rsquo;m not gonna say &ldquo;AI will replace all developers&rdquo; or &ldquo;everyone can build anything now&rdquo;; though the latter is becoming increasingly true.</p><p>Let me be clear. The system isn&rsquo;t magic. It made mistakes. It wrote code that needed refactoring.</p><p>But what surprised me was how the bottleneck wasn&rsquo;t at all the models capabilities.</p><p>It was <strong>how I structured the problem.</strong></p><p>When I gave clear, specific scopes to each agent, they executed extraordinarily well.</p><p>Conversely, when I was vague, it caused them to spiral, still producing working code, but their bar for quality dropped.</p><p>The quality of output correlated directly with the quality of problem decomposition.</p><p>That&rsquo;s a different skill than writing code.</p><p>It&rsquo;s effectively architecting systems in an organized feedback loop.</p><h2 id=why-this-matters>Why this matters<a hidden class=anchor aria-hidden=true href=#why-this-matters>#</a></h2><p>We often discuss AI progress in terms of model capabilities.</p><p>Which frontier model reasons the best, creates the best outputs, has the highest benchmark scores, etc.</p><p>But they are all so good now that you can disregard marginal gains one may receive by using a specific LLM.</p><p>Orchestration is becoming the most valuable skill, i.e. systems thinking.</p><p>Multi-agent systems aren&rsquo;t new conceptually. The idea of breaking work into specialized sub-tasks and coordinating them has been around for years.</p><p>What changed is that the models are now good enough (and inference is cheap enough) that orchestration actually works at a practical level.</p><p><a href=https://claude.com/customers/spotify>Spotify is now using this in production to resolve errors and conflicts.</a> It&rsquo;s become a critical part of their workflow, freeing up developer time for bigger-picture efforts.</p><p>The economics finally make sense.</p><h2 id=the-part-im-grappling-with>The part I&rsquo;m grappling with<a hidden class=anchor aria-hidden=true href=#the-part-im-grappling-with>#</a></h2><p>This creates real questions I don&rsquo;t have answers to yet.</p><p>If the skill shifts from <em>writing code</em> to <em>decomposing problems and directing agents</em> what does expertise mean?</p><p>How do we maintain quality when the barrier to shipping is this low?</p><p>What happens when non-technical people can orchestrate complex systems without understanding what&rsquo;s happening under the hood?</p><p>I used to believe the transition would be fairly gradual. Models getting better over years and workflows evolve incrementally, giving folks time to adapt.</p><p>But watching a multi-agent system go from nothing to a working product in an hour makes me realize the shift is more discontinuous than I expected.</p><p>At some point, you have to reflect on whether you are adapting or resisting.</p><hr><h2 id=history-as-context>History as context<a hidden class=anchor aria-hidden=true href=#history-as-context>#</a></h2><p>Developers used punch cards to program from the 1940s-1970s.</p><figure><img src=/images/punchcard-computer.jpeg alt="Punch Card Computer"><figcaption>IBM keypunch machine used to punch holes into paper cards for early computer data entry and programming</figcaption></figure><p>When CLIs and GUIs became standard, their expertise didn&rsquo;t disappear.</p><p>It simply evolved.</p><p>The ones who &ldquo;adapted&rdquo; were not the ones who memorized punch card syntax.</p><p>They were the ones who understood the underlying problems & learned the new abstractions.</p><p>Same pattern playing out again, just a different font.</p><p>The abstractions are shifting. The problems remain.</p><h2 id=what-im-doing-about-it>What I&rsquo;m doing about it<a hidden class=anchor aria-hidden=true href=#what-im-doing-about-it>#</a></h2><p>I&rsquo;m experimenting deliberately.</p><p>Reading everything I can. Building small swarms. Analyzing their points of failure. Talking to people who understand multi-agent architecture at a deeper level than I do.</p><p>Not at all because I&rsquo;m trying to stay ahead or worried about being left behind.</p><p>But because I&rsquo;m genuinely trying to understand what&rsquo;s actually possible versus what&rsquo;s hype.</p><p>And because the gap between demos and production reality is often massive.</p><h2 id=the-uncomfortable-truth>The uncomfortable truth<a hidden class=anchor aria-hidden=true href=#the-uncomfortable-truth>#</a></h2><p>I titled this &ldquo;I&rsquo;ve been drinking the AI kool-aid&rdquo; because that&rsquo;s what it feels like.</p><p>I&rsquo;m more optimistic about multi-agent systems than I expected to be.</p><p>But optimism without critical examination is just hype.</p><p>So what I&rsquo;m closely studying and paying attention to is:</p><ul><li>How do these systems maintain context over longer sessions (i.e. days/weeks)?</li><li>What is most optimal memory architecture to enable execution of more complex work?</li><li>When one agent makes a mistake, how does that cascade through the system?</li></ul><p>These are some of the problems exciting me that&rsquo;ve yet to be solved in the industry.</p><h2 id=my-perspective>My perspective<a hidden class=anchor aria-hidden=true href=#my-perspective>#</a></h2><p>I have no idea where this goes from here.</p><p>But I just experienced something that changed how I think about what&rsquo;s possible with current technology. It was imperative that I share it.</p><p>Right now, with the tools that exist today, anyone can semantically orchestrate an autonomous multi-agent swarm that builds working software in less than an hour.</p><p>That&rsquo;s worth your attention. Especially if you work in tech or aspire to.</p><p>The nature of the work is changing faster than most can adjust.</p><p>So what does this mean for us?</p><p>I&rsquo;m honestly trying to worry less about that.</p><p>I&rsquo;m much more concerned with challenging myself and feeding my curiosity, so my skills don&rsquo;t atrophy.</p><p>more from me soon</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://thegradient.ink/tags/multi-agents/>Multi-Agents</a></li><li><a href=https://thegradient.ink/tags/opinion/>Opinion</a></li><li><a href=https://thegradient.ink/tags/productivity/>Productivity</a></li><li><a href=https://thegradient.ink/tags/dev/>Dev</a></li></ul><nav class=paginav><a class=next href=https://thegradient.ink/posts/college-big-tech-reality/><span class=title>Next »</span><br><span>Why most college students won’t make it in big tech</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://thegradient.ink/>Gradient.</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>